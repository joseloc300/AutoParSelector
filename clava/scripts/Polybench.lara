import clava.autopar.Parallelize;
import clava.autopar.ParallelizeLoop;
import lara.Io;
import lara.util.LocalFolder;
import clava.ClavaJoinPoints;
import lara.cmake.CMaker;
import weaver.util.WeaverDataStore;
import lara.code.Timer;
import lara.metrics.ExecutionTimeMetric;
import weaver.Query;
import lara.Strings;

import CustomExecutionTimeMetric;
//import CustomParallelize;
import Utils;

aspectdef Polybench
	input
		sourceFolder,
		benchmarkFolders,
		now,
		readCache
	end

	var benchGroupName = "polybench-c-3.2";
	var start_time = performance.now();
	var nRuns = 3;
	var loopGroupSizeLimit = 2;
	var functionFilters = ["kernel_"];
	var problemSizeFlags3_2 = ["-DMINI_DATASET", "-DSMALL_DATASET", /*"-DSTANDARD_DATASET", "-DLARGE_DATASET", "-DEXTRALARGE_DATASET"*/];
	//var problemSizeFlags3_2 = ["-DMINI_DATASET", "-DSMALL_DATASET", "-DSTANDARD_DATASET", "-DLARGE_DATASET", "-DEXTRALARGE_DATASET"];
	var problemSizeFlags4_2 = ["-DMINI_DATASET", "-DSMALL_DATASET", "-DMEDIUM_DATASET", "-DLARGE_DATASET", "-DEXTRALARGE_DATASET"];

	var polybenchResults = createBenchGroupResultsObj(nRuns, loopGroupSizeLimit);

	var allFolders = ["datamining", "linear-algebra", "medley", "stencils"];
	var excludedFiles = [];
	var excludedFolders = ["fdtd-2d"];
	var benchmarks = getSubFolders(sourceFolder, benchmarkFolders, allFolders, excludedFiles, excludedFolders);

	polybenchResults["totalBenchmarks"] = benchmarks.length * problemSizeFlags3_2.length;

	var polybenchUtilsFolder = Io.getAbsolutePath(sourceFolder + "utilities/");
	var polybenchCPath = Io.getPath(polybenchUtilsFolder, "polybench.c");

	var xtraCs = [polybenchCPath];
	var xtraIncludeFolders = [polybenchUtilsFolder];

	println("Number of benchmarks found: " + benchmarks.length);
	println("Processing benchmarks");
	for (var benchmark of benchmarks) {
		println("Processing: " + benchmark.folder);

		for(var problemSizeFlag of problemSizeFlags3_2) {
			println("Current problem size flag = " + problemSizeFlag);
		
			Clava.pushAst();
			var flags = [problemSizeFlag];
			if(problemSizeFlag == "-DSTANDARD_DATASET") {
				flags = [];
			}
			rebuildCodeAst(benchmark, xtraCs, xtraIncludeFolders, flags);

			var parLoops;

			if(readCache) {
				parLoops = getParLoopsFromCache(benchmark, benchGroupName, problemSizeFlag);
			}
			else {
				Clava.pushAst();
				parLoops = getParLoops(functionFilters);
				Clava.popAst(); //NEW
				writeParLoopsToCache(benchmark, benchGroupName, problemSizeFlag, parLoops);
			}
	
			var benchmarkResults = createBenchResultsObj(benchmark, problemSizeFlag);
		
			polybenchResults["totalParLoops"] += Object.keys(parLoops).length;
	
			countLoopIterations(parLoops);

			var parLoopGroups = getParLoopGroups(parLoops, loopGroupSizeLimit);
			addLoopInfo(parLoops, benchmarkResults);
	
			polybenchResults["totalVersions"] += parLoopGroups.length;
			polybenchResults["totalRuns"] += parLoopGroups.length * nRuns;
			
			var version = 0;
			for (var loopGroup of parLoopGroups) {
				Clava.pushAst();
	
				addPragmas(loopGroup, parLoops);
	
				var measuresPar = addTimerPar(loopGroup, parLoops);
				var executorsPar = buildAndRun(benchmark, version, nRuns, true, problemSizeFlag);
				addResults(benchmarkResults, measuresPar, executorsPar, version, loopGroup, parLoops);
				version++;
				Clava.popAst();
			}
			
			var parLoopIds = Object.keys(parLoops);
	
			var measuresSeq = addTimerSeq(parLoopIds, parLoops);
			var executorsSeq = buildAndRun(benchmark, version, nRuns, false, problemSizeFlag);
			
			version = -1;
			addResults(benchmarkResults, measuresSeq, executorsSeq, version, loopGroup, parLoops);
			Clava.popAst();
			
			polybenchResults["benchmarks"].push(benchmarkResults);
			Io.writeJson(benchmark.outputFolder + problemSizeFlag + "/results.json", benchmarkResults);
		}
	}
	var end_time = performance.now();
	polybenchResults["totalExecutionTimeInSec"] = (end_time - start_time) / 1000;
	
	Io.writeJson("./results/" + benchGroupName + "_" + now.toISOString() + ".json", polybenchResults);
	println("Finished processing " + benchGroupName);

end
